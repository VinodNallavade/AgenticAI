{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff8dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "planner_prompt = PromptTemplate.from_template(\n",
    "    \"You are the Planner agent. Break down this task into steps:\\n{input}\"\n",
    ")\n",
    "\n",
    "research_prompt = PromptTemplate.from_template(\n",
    "    \"You are the Research agent. Use your tools to gather data for this plan:\\n{input}\"\n",
    ")\n",
    "\n",
    "coder_prompt = PromptTemplate.from_template(\n",
    "    \"You are the Coder agent. Write Python matplotlib code to generate the requested chart.\\nUse this research:\\n{input}\"\n",
    ")\n",
    "\n",
    "executor_prompt = PromptTemplate.from_template(\n",
    "    \"You are the Executor agent. Run the Python code provided and return printed output or errors:\\n{input}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6323c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "from langchain.tools.tavily_search import TavilySearchResults\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langgraph.graph import StateGraph\n",
    "from azure.identity import DefaultAzureCredential,get_bearer_token_provider\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langgraph.types import Command\n",
    "\n",
    "token_provider = get_bearer_token_provider(DefaultAzureCredential(),\"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_APIKEY\")\n",
    "\n",
    "\n",
    "# 1. Define shared AgentState\n",
    "class AgentState(BaseModel):\n",
    "    input: str\n",
    "    plan: Optional[str] = None\n",
    "    research: Optional[str] = None\n",
    "    search_results: Optional[str] = None\n",
    "    output: Optional[str] = None\n",
    "    execution_result: Optional[str] = None\n",
    "\n",
    "\n",
    "# 2. Initialize LLM\n",
    "llm = AzureChatOpenAI(\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_endpoint=\"https://azopenai-langchain.openai.azure.com/\",\n",
    "    azure_ad_token_provider= token_provider,\n",
    "    model= \"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "\n",
    "# 3. Define Tavily web search tool using @tool decorator\n",
    "@tool(\"tavily_web_search\")\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Perform a web search using Tavily with the given query string.\n",
    "    Returns combined search results as a text string.\n",
    "    \"\"\"\n",
    "    print(\"ðŸ•¸ï¸ Tavily Web Search tool called with query:\", query)\n",
    "    try:\n",
    "        results = TavilySearchResults(max_results=4, tavily_api_key=TAVILY_API_KEY).invoke(query)\n",
    "        if results:\n",
    "            # Combine first few results content or just first one\n",
    "            combined = \"\\n\\n\".join(r[\"content\"] for r in results)\n",
    "            return combined\n",
    "        else:\n",
    "            return \"No results found.\"\n",
    "    except Exception as e:\n",
    "        print(\"Error in Tavily search:\", e)\n",
    "        return f\"Error in Tavily search: {e}\"\n",
    "\n",
    "\n",
    "# 4. Wrap PythonREPL as tool using @tool\n",
    "python_repl_instance = PythonREPL()\n",
    "\n",
    "@tool(\"python_repl\")\n",
    "def python_repl_tool(code: str) -> str:\n",
    "    \"\"\"\n",
    "    Execute Python code using a Python REPL environment.\n",
    "    Returns the printed output or error messages from code execution.\n",
    "    \"\"\"\n",
    "    print(\"ðŸ PythonREPL tool running code...\")\n",
    "    return python_repl_instance.run(code)\n",
    "\n",
    "\n",
    "# 5. Create agents and executors\n",
    "planner_agent = create_react_agent(llm, tools=[], prompt=planner_prompt)\n",
    "research_agent = create_react_agent(llm, tools=[web_search], prompt=research_prompt)\n",
    "coder_agent = create_react_agent(llm, tools=[], prompt=coder_prompt)\n",
    "executor_agent = create_react_agent(llm, tools=[python_repl_tool], prompt=executor_prompt)\n",
    "\n",
    "\n",
    "planner_executor = AgentExecutor(agent=planner_agent, tools=[], verbose=True)\n",
    "research_executor = AgentExecutor(agent=research_agent, tools=[web_search], verbose=True)\n",
    "coder_executor = AgentExecutor(agent=coder_agent, tools=[], verbose=True)\n",
    "executor_executor = AgentExecutor(agent=executor_agent, tools=[python_repl_tool], verbose=True)\n",
    "\n",
    "\n",
    "# 6. Define node functions with handoffs\n",
    "\n",
    "def planner_node(state: AgentState):\n",
    "    \"\"\"\n",
    "    Planner agent: Break down the user's input task into clear actionable steps.\n",
    "    Updates state.plan with the generated plan.\n",
    "    Returns a command to handoff control to the Research agent.\n",
    "    \"\"\"\n",
    "    print(\"ðŸ§  Planner Agent Running...\")\n",
    "    result = planner_executor.invoke({\"input\": f\"Break this task into clear steps: {state.input}\"})\n",
    "    new_state = state.copy(update={\"plan\": result[\"output\"]})\n",
    "    return Command.goto(\"researcher\", state=new_state)\n",
    "\n",
    "def research_node(state: AgentState):\n",
    "    \"\"\"\n",
    "    Research agent: Use the plan or input to query Tavily web search tool.\n",
    "    Updates state.research and state.search_results with search data.\n",
    "    Returns a command to handoff control to the Coder agent.\n",
    "    \"\"\"    \n",
    "    print(\"ðŸ” Research Agent Running...\")\n",
    "    # Use plan or input as query\n",
    "    query = state.plan or state.input\n",
    "    result = research_executor.invoke({\"input\": query})\n",
    "    new_state = state.copy(update={\"research\": result[\"output\"], \"search_results\": result[\"output\"]})\n",
    "    return Command.goto(\"coder\", state=new_state)\n",
    "\n",
    "def coder_node(state: AgentState):\n",
    "    \"\"\"\n",
    "    Coder agent: Generate Python matplotlib code to draw the requested chart\n",
    "    using the research data from state.research.\n",
    "    Updates state.output with the generated Python code.\n",
    "    Returns a command to handoff control to the Executor agent.\n",
    "    \"\"\"\n",
    "    print(\"ðŸ’» Coder Agent Running...\")\n",
    "    prompt = (\n",
    "        \"Write complete Python code using matplotlib to draw the requested chart.\\n\"\n",
    "        \"Use this research:\\n\"\n",
    "        f\"{state.research}\\n\"\n",
    "        \"Include data inline, and end with plt.show() to display the chart.\\n\"\n",
    "        \"Only output the code without explanations.\"\n",
    "    )\n",
    "    result = coder_executor.invoke({\"input\": prompt})\n",
    "    new_state = state.copy(update={\"output\": result[\"output\"]})\n",
    "    return Command.goto(\"executor\", state=new_state)\n",
    "\n",
    "def executor_node(state: AgentState):\n",
    "    \"\"\"\n",
    "    Executor agent: Run the Python code stored in state.output using PythonREPL.\n",
    "    Updates state.execution_result with the output or error messages.\n",
    "    Returns the final updated state ending the multi-agent flow.\n",
    "    \"\"\"\n",
    "    print(\"âš™ï¸ Executor Agent Running...\")\n",
    "    try:\n",
    "        result = executor_executor.invoke({\"input\": state.output})\n",
    "        exec_output = result.get(\"output\", \"\")\n",
    "    except Exception as e:\n",
    "        exec_output = f\"Error during execution: {e}\"\n",
    "    new_state = state.copy(update={\"execution_result\": exec_output})\n",
    "    # End of chain, no next node\n",
    "    return new_state\n",
    "\n",
    "\n",
    "# 7. Build and compile graph\n",
    "\n",
    "builder = StateGraph(AgentState)\n",
    "builder.add_node(\"planner\", planner_node)\n",
    "builder.add_node(\"researcher\", research_node)\n",
    "builder.add_node(\"coder\", coder_node)\n",
    "builder.add_node(\"executor\", executor_node)\n",
    "\n",
    "builder.set_entry_point(\"planner\")\n",
    "builder.set_finish_point(\"executor\")\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "\n",
    "# 8. Run the multi-agent graph\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    task = \"Draw a line chart of India's GDP from 2013 to 2023\"\n",
    "\n",
    "    initial_state = AgentState(input=task)\n",
    "\n",
    "    final_state = graph.invoke(initial_state)\n",
    "\n",
    "    print(\"\\n=== Generated Python Code ===\\n\")\n",
    "    print(final_state.output)\n",
    "\n",
    "    print(\"\\n=== Execution Result (prints/errors) ===\\n\")\n",
    "    print(final_state.execution_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c37e7e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "PydanticUserError",
     "evalue": "Field 'name' defined on a base class was overridden by a non-annotated attribute. All field definitions, including overrides, require a type annotation.\n\nFor further information visit https://errors.pydantic.dev/2.11/u/model-field-overridden",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPydanticUserError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseTool\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrequests\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mTavilySearchTool\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mBaseTool\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtavily_search\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSearch the web using Tavily for factual data.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AgenticAI\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_model_construction.py:112\u001b[39m, in \u001b[36mModelMetaclass.__new__\u001b[39m\u001b[34m(mcs, cls_name, bases, namespace, __pydantic_generic_metadata__, __pydantic_reset_parent_namespace__, _create_model_module, **kwargs)\u001b[39m\n\u001b[32m    110\u001b[39m config_wrapper = ConfigWrapper.for_model(bases, namespace, kwargs)\n\u001b[32m    111\u001b[39m namespace[\u001b[33m'\u001b[39m\u001b[33mmodel_config\u001b[39m\u001b[33m'\u001b[39m] = config_wrapper.config_dict\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m private_attributes = \u001b[43minspect_namespace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_wrapper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mignored_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_field_names\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m private_attributes \u001b[38;5;129;01mor\u001b[39;00m base_private_attributes:\n\u001b[32m    116\u001b[39m     original_model_post_init = get_model_post_init(namespace, bases)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AgenticAI\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_model_construction.py:449\u001b[39m, in \u001b[36minspect_namespace\u001b[39m\u001b[34m(namespace, ignored_types, base_class_vars, base_class_fields)\u001b[39m\n\u001b[32m    447\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m var_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m raw_annotations:\n\u001b[32m    448\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m var_name \u001b[38;5;129;01min\u001b[39;00m base_class_fields:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[32m    450\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mField \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m defined on a base class was overridden by a non-annotated attribute. \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    451\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mAll field definitions, including overrides, require a type annotation.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    452\u001b[39m             code=\u001b[33m'\u001b[39m\u001b[33mmodel-field-overridden\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    453\u001b[39m         )\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, FieldInfo):\n\u001b[32m    455\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[32m    456\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mField \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m requires a type annotation\u001b[39m\u001b[33m'\u001b[39m, code=\u001b[33m'\u001b[39m\u001b[33mmodel-field-missing-annotation\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    457\u001b[39m         )\n",
      "\u001b[31mPydanticUserError\u001b[39m: Field 'name' defined on a base class was overridden by a non-annotated attribute. All field definitions, including overrides, require a type annotation.\n\nFor further information visit https://errors.pydantic.dev/2.11/u/model-field-overridden"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Literal\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain.tools import Tool\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.graph import MessagesState, END, Graph\n",
    "from langgraph.types import Command\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "token_provider = get_bearer_token_provider(DefaultAzureCredential(),\"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "\n",
    "# --- Initialize AzureChatOpenAI LLM ---\n",
    "llm = AzureChatOpenAI(\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_endpoint=\"https://azopenai-langchain.openai.azure.com/\",\n",
    "    azure_ad_token_provider=token_provider,\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "# --- Tavily Tool ---\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_APIKEY\")\n",
    "assert TAVILY_API_KEY, \"Set TAVILY_APIKEY in your .env\"\n",
    "\n",
    "from langchain.tools import BaseTool\n",
    "\n",
    "import requests\n",
    "\n",
    "class TavilySearchTool(BaseTool):\n",
    "    name = \"tavily_search\"\n",
    "    description = \"Search the web using Tavily for factual data.\"\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "        # Real Tavily API call\n",
    "        headers = {\"Authorization\": f\"Bearer {TAVILY_API_KEY}\"}\n",
    "        payload = {\"query\": query, \"max_results\": 4}\n",
    "        response = requests.post(\"https://api.tavily.com/v1/search\", json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        # Extract content from results and format as string\n",
    "        results = data.get(\"results\", [])\n",
    "        output = \"\\n\".join([f\"- {item.get('content','')}\" for item in results])\n",
    "        return output\n",
    "\n",
    "    async def _arun(self, query: str) -> str:\n",
    "        raise NotImplementedError(\"Async not implemented\")\n",
    "\n",
    "tavily_tool = TavilySearchTool()\n",
    "\n",
    "# --- Python REPL Tool ---\n",
    "python_repl = PythonREPL()\n",
    "\n",
    "def python_repl_func(code: str) -> str:\n",
    "    try:\n",
    "        return python_repl.run(code)\n",
    "    except Exception as e:\n",
    "        return f\"Error executing code: {e}\"\n",
    "\n",
    "python_repl_tool = Tool(\n",
    "    name=\"python_repl\",\n",
    "    func=python_repl_func,\n",
    "    description=\"Execute Python code and return the printed output or errors.\"\n",
    ")\n",
    "\n",
    "# --- Helper function to detect final answer ---\n",
    "def get_next_node(last_message: BaseMessage, goto: str):\n",
    "    if \"FINAL ANSWER\" in last_message.content:\n",
    "        return END\n",
    "    return goto\n",
    "\n",
    "def make_system_prompt(suffix: str) -> str:\n",
    "    return (\n",
    "        \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "        \" Use the provided tools to progress towards answering the question.\"\n",
    "        \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
    "        \" will help where you left off. Execute what you can to make progress.\"\n",
    "        \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "        \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
    "        f\"\\n{suffix}\"\n",
    "    )\n",
    "\n",
    "# --- Agent Prompts ---\n",
    "planner_prompt = make_system_prompt(\n",
    "    \"You are the Planner agent. Break down the user task into clear steps. \"\n",
    "    \"Work with Research, Coder, and Executor colleagues.\"\n",
    ")\n",
    "\n",
    "research_prompt = make_system_prompt(\n",
    "    \"You can only do research. You are working with Planner, Coder, and Executor colleagues.\"\n",
    ")\n",
    "\n",
    "coder_prompt = make_system_prompt(\n",
    "    \"You can only write Python matplotlib code to generate charts. \"\n",
    "    \"You are working with Planner, Research, and Executor colleagues.\"\n",
    ")\n",
    "\n",
    "executor_prompt = make_system_prompt(\n",
    "    \"You execute Python code and return printed output. \"\n",
    "    \"You work with Planner, Research, and Coder colleagues.\"\n",
    ")\n",
    "\n",
    "# --- Create agents ---\n",
    "planner_agent = create_react_agent(llm, tools=[], prompt=planner_prompt)\n",
    "research_agent = create_react_agent(llm, tools=[tavily_tool], prompt=research_prompt)\n",
    "coder_agent = create_react_agent(llm, tools=[python_repl_tool], prompt=coder_prompt)\n",
    "executor_agent = create_react_agent(llm, tools=[python_repl_tool], prompt=executor_prompt)\n",
    "\n",
    "# --- Define nodes ---\n",
    "def planner_node(state: MessagesState) -> Command[Literal[\"research\", END]]:\n",
    "    result = planner_agent.invoke(state)\n",
    "    goto = get_next_node(result[\"messages\"][-1], \"research\")\n",
    "    result[\"messages\"][-1] = HumanMessage(content=result[\"messages\"][-1].content, name=\"planner\")\n",
    "    return Command(update={\"messages\": result[\"messages\"]}, goto=goto)\n",
    "\n",
    "def research_node(state: MessagesState) -> Command[Literal[\"coder\", END]]:\n",
    "    result = research_agent.invoke(state)\n",
    "    goto = get_next_node(result[\"messages\"][-1], \"coder\")\n",
    "    result[\"messages\"][-1] = HumanMessage(content=result[\"messages\"][-1].content, name=\"researcher\")\n",
    "    return Command(update={\"messages\": result[\"messages\"]}, goto=goto)\n",
    "\n",
    "def coder_node(state: MessagesState) -> Command[Literal[\"executor\", END]]:\n",
    "    result = coder_agent.invoke(state)\n",
    "    goto = get_next_node(result[\"messages\"][-1], \"executor\")\n",
    "    result[\"messages\"][-1] = HumanMessage(content=result[\"messages\"][-1].content, name=\"coder\")\n",
    "    return Command(update={\"messages\": result[\"messages\"]}, goto=goto)\n",
    "\n",
    "def executor_node(state: MessagesState) -> Command[Literal[\"planner\", END]]:\n",
    "    result = executor_agent.invoke(state)\n",
    "    goto = get_next_node(result[\"messages\"][-1], \"planner\")\n",
    "    result[\"messages\"][-1] = HumanMessage(content=result[\"messages\"][-1].content, name=\"executor\")\n",
    "    return Command(update={\"messages\": result[\"messages\"]}, goto=goto)\n",
    "\n",
    "# --- Setup graph ---\n",
    "graph = Graph(\n",
    "    nodes={\n",
    "        \"planner\": planner_node,\n",
    "        \"research\": research_node,\n",
    "        \"coder\": coder_node,\n",
    "        \"executor\": executor_node,\n",
    "    },\n",
    "    start_node=\"planner\"\n",
    ")\n",
    "\n",
    "# --- Run multi-agent loop ---\n",
    "def run_multi_agent_loop(user_input: str):\n",
    "    state = MessagesState(messages=[HumanMessage(content=user_input, name=\"user\")])\n",
    "    current_node = graph.start_node\n",
    "\n",
    "    while current_node != END:\n",
    "        node_func = graph.nodes[current_node]\n",
    "        command = node_func(state)\n",
    "        state = MessagesState(messages=command.update[\"messages\"])\n",
    "        current_node = command.goto\n",
    "\n",
    "    print(\"Multi-agent process finished.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_question = \"Draw line chart for GDP in India for the last decade.\"\n",
    "    run_multi_agent_loop(user_question)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
